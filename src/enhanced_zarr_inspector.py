#!/usr/bin/env python
#
# enhanced_zarr_inspector.py
# Enhanced script to inspect the structure and metadata of Zarr archives 
# generated by both original and enhanced fish tracking pipelines.
#
# Usage: python enhanced_zarr_inspector.py /path/to/your/data.zarr
#
import zarr
import argparse
import json
import os
import numpy as np
from rich.console import Console
from rich.table import Table
from rich.tree import Tree
from rich import box
from rich.panel import Panel
from rich.columns import Columns

# --- Helper Function ---
def format_bytes(size: int) -> str:
    """Converts bytes to a human-readable format (KB, MB, GB)."""
    if size is None or size == 0:
        return "0 B"
    power = 1024
    n = 0
    power_labels = {0: '', 1: 'K', 2: 'M', 3: 'G', 4: 'T'}
    while size >= power and n < len(power_labels) - 1:
        size /= power
        n += 1
    return f"{size:.2f} {power_labels[n]}B"

def detect_pipeline_version(root):
    """Detect whether this is original or enhanced pipeline data."""
    if 'tracking/tracking_results' in root:
        tracking_results = root['tracking/tracking_results']
        if 'column_names' in tracking_results.attrs:
            column_names = tracking_results.attrs['column_names']
            if len(column_names) >= 20 and 'bbox_x_norm_ds' in column_names:
                return 'enhanced', column_names
            elif len(column_names) == 9:
                return 'original', column_names
    return 'unknown', []

def inspect_yolo_readiness(root, pipeline_version):
    """Inspect YOLO training readiness."""
    console = Console()
    
    if pipeline_version == 'enhanced':
        panel_content = []
        panel_content.append(f"‚úÖ Enhanced multi-scale tracking data found")
        
        # Check tracking results for YOLO-ready data
        if 'tracking/tracking_results' in root:
            tracking_results = root['tracking/tracking_results']
            column_names = tracking_results.attrs.get('column_names', [])
            
            # Count available coordinate systems
            coord_systems = []
            if 'bbox_x_norm_ds' in column_names:
                coord_systems.append("640√ó640 (YOLO-ready)")
            if 'bbox_x_norm_full' in column_names:
                coord_systems.append("4512√ó4512 (full-res)")
            if 'bladder_x_roi_norm' in column_names:
                coord_systems.append("ROI normalized")
            
            panel_content.append(f"üìê Coordinate systems: {len(coord_systems)}")
            for system in coord_systems:
                panel_content.append(f"   ‚Ä¢ {system}")
            
            # Check for valid tracking data
            data = tracking_results[:]
            valid_frames = ~np.isnan(data[:, 0])  # Heading column
            tracked_frames = np.sum(valid_frames)
            total_frames = data.shape[0]
            
            panel_content.append(f"üìä Tracked frames: {tracked_frames}/{total_frames}")
            
            # Check coordinate systems documentation
            if 'tracking/coordinate_systems' in root:
                coord_systems_count = len(root['tracking/coordinate_systems'].attrs)
                panel_content.append(f"üìã Coordinate documentation: {coord_systems_count} systems")
            
            panel_content.append("üéØ Ready for flexible YOLO dataset generation!")
            panel_content.append("üí° Use generate_yolo_dataset.py to create custom training splits")
            
        else:
            panel_content = [
                "‚ö†Ô∏è  No tracking results found",
                "üí° Run enhanced pipeline with --stage track"
            ]
    else:
        panel_content = [
            "üìä Original pipeline format detected",
            "üîÑ Coordinate transformation needed for YOLO training",
            "üí° Consider running enhanced pipeline for multi-scale data"
        ]
    
    yolo_panel = Panel(
        "\n".join(panel_content),
        title="üéØ YOLO Training Readiness",
        border_style="green" if pipeline_version == 'enhanced' else "yellow"
    )
    
    console.print(yolo_panel)

def analyze_tracking_performance(root, column_names):
    """Analyze tracking performance and data quality."""
    console = Console()
    
    if 'tracking/tracking_results' not in root:
        console.print("‚ö†Ô∏è  No tracking results found")
        return
    
    tracking_results = root['tracking/tracking_results']
    data = tracking_results[:]
    
    # Basic statistics
    total_frames = data.shape[0]
    valid_frames = ~np.isnan(data[:, 0])  # Heading column
    tracked_frames = np.sum(valid_frames)
    success_rate = (tracked_frames / total_frames) * 100
    
    # Create performance table
    perf_table = Table(title="üìà Tracking Performance", box=box.ROUNDED)
    perf_table.add_column("Metric", style="cyan")
    perf_table.add_column("Value", style="green")
    
    perf_table.add_row("Total Frames", str(total_frames))
    perf_table.add_row("Successfully Tracked", str(tracked_frames))
    perf_table.add_row("Success Rate", f"{success_rate:.2f}%")
    
    # Enhanced metrics
    if len(column_names) >= 20:  # Enhanced format
        col_map = {name: i for i, name in enumerate(column_names)}
        
        if 'confidence_score' in col_map:
            confidence_scores = data[valid_frames, col_map['confidence_score']]
            perf_table.add_row("Avg Confidence", f"{np.mean(confidence_scores):.3f}")
            perf_table.add_row("Min Confidence", f"{np.min(confidence_scores):.3f}")
            perf_table.add_row("Max Confidence", f"{np.max(confidence_scores):.3f}")
        
        # Bounding box analysis
        if 'bbox_width_norm_ds' in col_map and 'bbox_height_norm_ds' in col_map:
            bbox_widths = data[valid_frames, col_map['bbox_width_norm_ds']]
            bbox_heights = data[valid_frames, col_map['bbox_height_norm_ds']]
            
            perf_table.add_row("Avg Fish Width", f"{np.mean(bbox_widths):.3f} (norm)")
            perf_table.add_row("Avg Fish Height", f"{np.mean(bbox_heights):.3f} (norm)")
            perf_table.add_row("Fish Size Std", f"w:{np.std(bbox_widths):.3f}, h:{np.std(bbox_heights):.3f}")
    
    console.print(perf_table)

def inspect_coordinate_systems(root):
    """Inspect coordinate system documentation."""
    console = Console()
    
    if 'tracking/coordinate_systems' not in root:
        console.print("‚ÑπÔ∏è  No coordinate system documentation found")
        return
    
    coord_group = root['tracking/coordinate_systems']
    
    console.print("\n[bold]üìê Coordinate Systems Documentation[/bold]")
    
    for coord_name, coord_info in coord_group.attrs.items():
        table = Table(title=f"Coordinate System: {coord_name}", box=box.MINIMAL)
        table.add_column("Property", style="cyan")
        table.add_column("Value", style="white")
        
        for key, value in coord_info.items():
            if isinstance(value, list):
                # Handle mixed types in lists
                try:
                    value_str = ", ".join(str(item) for item in value) if len(value) <= 3 else f"{len(value)} columns"
                except:
                    value_str = f"{len(value)} items"
            else:
                value_str = str(value)
            table.add_row(key, value_str)
        
        console.print(table)

# --- Core Inspection Functions (Enhanced) ---
def print_enhanced_attributes_table(console: Console, title: str, attributes: zarr.attrs.Attributes):
    """Enhanced attributes table with better formatting for pipeline metadata."""
    if not attributes:
        console.print(f"\n[bold]{title}[/bold]: (No attributes)")
        return

    table = Table(title=title, box=box.ROUNDED, show_header=True, header_style="bold magenta")
    table.add_column("Attribute Key", style="dim", width=35)
    table.add_column("Value")

    # Special handling for known pipeline attributes
    special_attrs = {
        'enhanced_pipeline_version', 'yolo_ready', 'enhanced_features',
        'coordinate_systems', 'summary_statistics'
    }

    for key, value in attributes.items():
        if isinstance(value, dict):
            if key == 'summary_statistics':
                # Special formatting for tracking statistics
                stats_str = f"Tracked: {value.get('frames_tracked', 'N/A')}/{value.get('total_frames', 'N/A')} ({value.get('percent_tracked', 'N/A'):.1f}%)"
                table.add_row(key, f"[green]{stats_str}[/green]")
            else:
                value_str = json.dumps(value, indent=2)
                table.add_row(key, value_str)
        elif key in special_attrs:
            # Highlight special pipeline attributes
            table.add_row(key, f"[bold green]{value}[/bold green]")
        else:
            table.add_row(key, str(value))

    console.print(table)

def print_enhanced_datasets_summary(console: Console, title: str, group: zarr.hierarchy.Group):
    """Enhanced dataset summary with pipeline-specific information."""
    datasets = {name: obj for name, obj in group.items() if isinstance(obj, zarr.core.Array)}

    if not datasets:
        console.print(f"\n[bold]{title}[/bold]: (No datasets in this group)")
        return

    table = Table(title=title, box=box.ROUNDED, show_header=True, header_style="bold magenta")
    table.add_column("Dataset Name", style="cyan", no_wrap=True)
    table.add_column("Shape", style="green")
    table.add_column("Chunks", style="yellow") 
    table.add_column("Dtype", style="blue")
    table.add_column("Size", style="red", justify="right")
    table.add_column("Pipeline Info", style="magenta")

    for name, dset in datasets.items():
        # Enhanced info based on dataset type
        extra_info = ""
        
        if name == 'tracking_results':
            if 'column_names' in dset.attrs:
                col_count = len(dset.attrs['column_names'])
                if col_count >= 20:
                    extra_info = f"Enhanced ({col_count} cols)"
                else:
                    extra_info = f"Original ({col_count} cols)"
        elif name in ['images_full', 'images_ds']:
            extra_info = f"Video data"
        elif name in ['roi_images']:
            extra_info = f"Fish crops"
        elif 'coordinates' in name:
            if 'full' in name:
                extra_info = "4512√ó4512 coords"
            elif 'ds' in name:
                extra_info = "640√ó640 coords"
            else:
                extra_info = "ROI coords"

        table.add_row(
            name,
            str(dset.shape),
            str(dset.chunks),
            str(dset.dtype),
            format_bytes(dset.nbytes),
            extra_info
        )
    console.print(table)

def build_enhanced_zarr_tree(group: zarr.hierarchy.Group, tree_branch: Tree):
    """Enhanced tree view with pipeline-specific icons and information."""
    group_items = sorted(list(group.groups()))
    dataset_items = sorted(list(group.arrays()))

    # Special icons for known pipeline components
    group_icons = {
        'raw_video': 'üé¨',
        'background_models': 'üñºÔ∏è ',
        'crop_data': '‚úÇÔ∏è ',
        'tracking': 'üéØ', 
        'coordinate_systems': 'üìê'
    }
    
    dataset_icons = {
        'images_full': 'üìπ',
        'images_ds': 'üì∫',
        'roi_images': 'üîç',
        'tracking_results': 'üìä'
    }

    for name, grp_obj in group_items:
        icon = group_icons.get(name, ':file_folder:')
        branch = tree_branch.add(f"{icon} [bold blue]{name}/[/bold blue]")
        build_enhanced_zarr_tree(grp_obj, branch)
    
    for name, arr_obj in dataset_items:
        icon = dataset_icons.get(name, ':page_facing_up:')
        tree_branch.add(f"{icon} [green]{name}[/green]  [dim]({arr_obj.shape}, {arr_obj.dtype})[/dim]")

def inspect_enhanced_zarr_archive(zarr_path: str):
    """Enhanced Zarr inspection with pipeline-specific analysis."""
    console = Console()
    console.rule(f"[bold]üî¨ Enhanced Zarr Inspector: {os.path.abspath(zarr_path)}[/bold]", style="bold white")

    if not os.path.exists(zarr_path):
        console.print(f"\n[bold red]Error:[/bold red] Path does not exist: '{zarr_path}'")
        return
        
    try:
        root = zarr.open(zarr_path, mode='r')
    except Exception as e:
        console.print(f"\n[bold red]Error:[/bold red] Could not open Zarr archive at '{zarr_path}'.")
        console.print(f"Details: {e}")
        return

    # Detect pipeline version
    pipeline_version, column_names = detect_pipeline_version(root)
    
    # Pipeline version banner
    if pipeline_version == 'enhanced':
        banner = Panel(
            "üöÄ Enhanced Fish Tracking Pipeline Data\n"
            "‚úÖ Multi-scale coordinates\n"
            "‚úÖ Comprehensive bounding box data\n" 
            "‚úÖ Ready for flexible YOLO dataset generation",
            title="Pipeline Version",
            border_style="green"
        )
    elif pipeline_version == 'original':
        banner = Panel(
            "üìä Original Fish Tracking Pipeline Data\n"
            "‚ÑπÔ∏è  Single-scale coordinates\n"
            "‚ö†Ô∏è  Requires transformation for YOLO training",
            title="Pipeline Version", 
            border_style="yellow"
        )
    else:
        banner = Panel(
            "‚ùì Unknown or custom pipeline data format",
            title="Pipeline Version",
            border_style="red"
        )
    
    console.print(banner)

    # 1. Print the overall structure tree
    console.print("\n[bold]üå≥ Archive Structure[/bold]")
    tree = Tree("[bold cyan]root[/bold cyan]")
    build_enhanced_zarr_tree(root, tree)
    console.print(tree)
    console.rule(style="white")

    # 2. Pipeline-specific analyses
    inspect_yolo_readiness(root, pipeline_version)
    analyze_tracking_performance(root, column_names)
    inspect_coordinate_systems(root)

    # 3. Inspect each group with enhanced formatting
    groups_to_inspect = [('/', root)] + sorted([(name, grp) for name, grp in root.groups()])

    for name, group in groups_to_inspect:
        title = f"Inspecting Group: '{name}'"
        console.print(f"\n\n[bold white on blue] {title.center(80)} [/bold white on blue]")
        
        print_enhanced_attributes_table(console, f"Attributes for Group '{name}'", group.attrs)
        print_enhanced_datasets_summary(console, f"Datasets in Group '{name}'", group)

def main():
    parser = argparse.ArgumentParser(
        description="Enhanced inspector for fish tracking Zarr archives with pipeline-specific analysis.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("zarr_path", type=str, help="Path to the Zarr archive directory to inspect.")
    args = parser.parse_args()

    inspect_enhanced_zarr_archive(args.zarr_path)

if __name__ == "__main__":
    main()