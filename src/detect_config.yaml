# ================================================================================
# COMPREHENSIVE MULTI-ZARR YOLO TRAINING CONFIGURATION
# ================================================================================

# --- Dummy paths for YOLOv8 trainer compatibility ---
# Our custom dataloader ignores these paths, but they are required to pass initial checks.
train: ./
val: ./
nc: 1
names: ['fish']

# Part 1: DATA CONFIGURATION
# --------------------------------------------------------------------------------
data_config:
  zarr_paths:
    - /home/delahantyj@hhmi.org/Desktop/training_data_2/20250731_omnifin0_arena4.zarr
  task: detect
  split_ratio: 0.8
  random_seed: 42

  # sampling_strategy: Defines how to sample from multiple zarr_paths.
  #
  # --- Available Strategies ---
  # "balanced": (Default) Takes an equal number of samples from each dataset,
  #             matching the size of the smallest one. Prevents larger
  #             datasets from dominating the training.
  #
  # "proportional": Uses all available valid frames from all datasets. The number
  #                 of samples from each dataset will be proportional to its size.
  #
  # "weighted":     Allows you to manually define the importance of each dataset.
  #                 Requires the 'dataset_weights' dictionary below.
  #
  sampling_strategy: balanced

  # --- Example for 'weighted' strategy ---
  # To use this, set sampling_strategy to "weighted" and uncomment the following lines.
  # The keys must match the names of your zarr files (without the .zarr extension).
  # The weights are relative. For example, a weight of 1.0 for 'video1' and 2.0 for
  # 'video2' means you want twice as many samples from 'video2' relative to 'video1',
  # assuming enough valid frames are available.
  #
  # dataset_weights:
  #   video1: 1.0
  #   video2: 2.0


# Part 2: MODEL & TRAINING HYPERPARAMETERS
# --------------------------------------------------------------------------------
training_params:
  # Model setup
  model: yolov8n.pt

  # Core hyperparameters
  epochs: 100 # Number of training epochs
  batch: 48 # Batch size for training
  imgsz: 640 # Input image size for training
  lr0: 0.002 # Initial learning rate
  momentum: 0.9 # Momentum factor
  weight_decay: 0.0005 # Weight decay (L2 penalty)
  patience: 10 # Early stopping patience
  device: '0' # CUDA device

# ================================================================================
# Part 3: TRAINING HISTORY & METADATA
# This section is automatically populated by the training script after a run.
# ================================================================================
training_history:
  # --- Run Details ---
  training_run_name: "multi_zarr_train_example"
  output_directory: "runs/detect/multi_zarr_train_example"
  final_model_path: "runs/detect/multi_zarr_train_example/weights/best.pt"
  training_start_time: "2025-07-28 17:00:00"
  training_duration_hours: 0.5

  # --- Code & Environment ---
  git_commit_hash: ""
  python_version: ""
  torch_version: ""
  ultralytics_version: ""

  # --- Final Validation Metrics ---
  final_metrics:
    box_loss: 0.0000
    cls_loss: 0.0000
    dfl_loss: 0.0000
    precision: 0.0000
    recall: 0.0000
    mAP50: 0.0000
    mAP50_95: 0.0000
