# enhanced_multi_zarr_config.yaml
# Professional Multi-Zarr YOLO Configuration
# Enhanced version with comprehensive options for your fish tracking project

# ================================================================================
# DATASET CONFIGURATION
# ================================================================================

# Zarr file paths (update these to match your actual paths)
zarr_paths:
  - "/home/delahantyj@hhmi.org/Desktop/concentricOMR3/longer_edge.zarr"
  - "/home/delahantyj@hhmi.org/Desktop/concentricOMR3/video.zarr"

# ================================================================================
# SAMPLING STRATEGY CONFIGURATION
# ================================================================================

# Sampling strategy options:
#   - "balanced": Equal representation from each dataset (recommended for mixed videos)
#   - "proportional": Proportional to dataset size (natural distribution)
#   - "weighted": Custom weights per dataset (see dataset_weights below)
#   - "quality": Weight by tracking success rate (favor higher-quality data)
sampling_strategy: "balanced"

# Custom dataset weights (only used if sampling_strategy is "weighted")
# Format: {dataset_name: weight}
# Example weights (uncomment and adjust as needed):
# dataset_weights:
#   longer_edge: 1.0    # Standard weight
#   video: 1.2          # 20% more samples from this video
#   # Add more datasets as needed

# ================================================================================
# TRAINING CONFIGURATION
# ================================================================================

# Task type
task: "detect"  # Options: "detect" (640x640 full images), "pose" (320x320 ROI crops)

# Target image size (auto-set based on task if not specified)
# target_size: 640  # Uncomment to override default

# Train/validation split ratio
split_ratio: 0.8  # 80% train, 20% validation

# Random seed for reproducible splits
random_seed: 42

# Minimum confidence threshold (only for enhanced format datasets)
min_confidence: 0.0  # Filter out low-confidence detections

# Balance across videos (ensure train/val both have all videos represented)
balance_across_videos: true

# ================================================================================
# YOLO TRAINING PARAMETERS
# ================================================================================

# Standard YOLO parameters (used by ultralytics)
# These are passed to the YOLO trainer

# Number of classes (required by YOLO)
nc: 1

# Class names (required by YOLO)
names:
  - fish

# Training and validation paths (handled by our custom dataset loader)
train: ./  # Placeholder - handled by custom dataset
val: ./    # Placeholder - handled by custom dataset

# ================================================================================
# ADVANCED CONFIGURATION
# ================================================================================

# Performance optimizations
performance:
  # Number of data loading workers (auto-calculated based on number of videos)
  # workers: 8  # Uncomment to override auto-calculation
  
  # Batch size considerations
  recommended_batch_sizes:
    # Adjust based on your GPU memory
    # RTX 3080/3090: 16-32
    # RTX 4080/4090: 32-64
    # A100: 64-128
    gpu_8gb: 16
    gpu_12gb: 24
    gpu_16gb: 32
    gpu_24gb: 48

# Monitoring and debugging
monitoring:
  # Save detailed per-dataset metrics during training
  track_per_dataset_metrics: true
  
  # Log sampling statistics
  log_sampling_stats: true
  
  # Create training visualizations
  create_plots: true

# Data quality controls
quality_controls:
  # Skip frames with missing keypoints
  require_valid_keypoints: false
  
  # Skip frames with extreme bounding box sizes
  bbox_size_limits:
    min_width: 0.01   # 1% of image width
    max_width: 0.8    # 80% of image width
    min_height: 0.01  # 1% of image height
    max_height: 0.8   # 80% of image height

# ================================================================================
# EXPERIMENTAL FEATURES
# ================================================================================

# experimental:
#   # Enable experimental features (use with caution)
#   enable_experimental: false
  
#   # Dynamic resampling during training
#   dynamic_resampling: false
  
#   # Adaptive quality weighting
#   adaptive_quality_weighting: false

# ================================================================================
# TRAINING RECOMMENDATIONS
# ================================================================================

# # Recommended training commands:
# training_examples: |
  
#   # Basic training (50 epochs)
#   python enhanced_multi_zarr_trainer.py enhanced_multi_zarr_config.yaml --epochs 50
  
#   # Extended training with larger model
#   python enhanced_multi_zarr_trainer.py enhanced_multi_zarr_config.yaml \
#     --model yolov8s.pt --epochs 100 --batch-size 24
  
#   # Production training with full monitoring
#   python enhanced_multi_zarr_trainer.py enhanced_multi_zarr_config.yaml \
#     --model yolov8m.pt --epochs 200 --batch-size 16 \
#     --project ./fish_detection_experiments \
#     --name multi_video_balanced_v1
  
#   # Quick test run
#   python enhanced_multi_zarr_trainer.py enhanced_multi_zarr_config.yaml \
#     --epochs 5 --batch-size 8

# # Expected results with your data:
# expected_performance: |
  
#   Based on your zarr files:
#   - longer_edge.zarr: ~8,283 training samples (84.6%)
#   - video.zarr: ~1,506 training samples (15.4%)
  
#   With balanced sampling:
#   - Each dataset contributes equally (50%/50%)
#   - Total training samples: ~3,012 (1,506 from each)
  
#   Recommended training progression:
#   1. Start with 50 epochs to validate setup
#   2. Scale to 100-200 epochs for production model
#   3. Experiment with different sampling strategies
#   4. Try larger models (yolov8s/m) for better accuracy

# ================================================================================
# TROUBLESHOOTING
# ================================================================================

# troubleshooting: |
  
#   Common issues and solutions:
  
#   1. "Zarr files not compatible":
#      - Ensure both zarr files have the same data format (enhanced/original)
#      - Check that column names match across files
#      - Verify image shapes are consistent
  
#   2. "No valid frames found":
#      - Check min_confidence threshold (try 0.0)
#      - Verify tracking results contain valid data
#      - Review data quality in zarr files
  
#   3. "Out of memory during training":
#      - Reduce batch_size (try 8 or 4)
#      - Use smaller model (yolov8n.pt)
#      - Reduce number of workers
  
#   4. "Training very slow":
#      - Increase batch_size if memory allows
#      - Ensure persistent_workers=True
#      - Check disk I/O performance
  
#   5. "Unbalanced dataset warning":
#      - Consider using "balanced" sampling strategy
#      - Adjust dataset_weights if using "weighted" strategy
#      - Review per-dataset metrics in training logs

# ================================================================================
# METADATA
# ================================================================================

# Configuration metadata
# metadata:
#   version: "2.0"
#   created_for: "concentricOMR3 fish tracking project"
#   last_updated: "2024-12-28"
#   compatible_with:
#     - "Enhanced Multi-Zarr YOLO Dataset v2.0+"
#     - "YOLOv8 (ultralytics)"
#     - "PyTorch 1.9+"